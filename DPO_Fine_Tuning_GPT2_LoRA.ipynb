{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-intro",
   "metadata": {},
   "source": [
    "# Direct Preference Optimization (DPO) Fine-Tuning\n",
    "\n",
    "In this model we fine-tune a language model using Direct Preference Optimization (DPO), a technique for aligning language models with human preferences without requiring a separate reward model.\n",
    "\n",
    "## Overview\n",
    "- **Model**: GPT-2\n",
    "- **Technique**: DPO with LoRA (Low-Rank Adaptation) for parameter-efficient fine-tuning\n",
    "- **Dataset**: UltraFeedback Binarized - a preference dataset with chosen/rejected response pairs\n",
    "\n",
    "## Requirements\n",
    "- Python 3.9+\n",
    "- PyTorch 2.x\n",
    "- CUDA-capable GPU (optional, but recommended for faster training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94521bb-99e8-4852-a16d-fb95aea29460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (versions compatible with PyTorch 2.9.1)\n",
    "!pip install torch==2.9.1\n",
    "!pip install transformers>=4.57.0 trl>=0.25.0 peft>=0.14.0 accelerate\n",
    "!pip install datasets matplotlib pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f2fce-8af8-4e96-af61-527c16d94da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    GPT2Tokenizer,\n",
    "    set_seed,\n",
    "    GenerationConfig\n",
    ")\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "# Check device availability\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-quant-header",
   "metadata": {},
   "source": [
    "## Model Loading\n",
    "\n",
    "The following cell loads the model with optional 4-bit quantization. Quantization will significantly reduces memory usage but does **require a CUDA GPU**. If running on CPU, the model will load in full precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e026d4-1122-470a-93bd-741493d17abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with optional quantization (GPU only)\n",
    "use_quantization = torch.cuda.is_available()\n",
    "\n",
    "if use_quantization:\n",
    "    # Install bitsandbytes for quantization (CUDA only)\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"-U\", \"bitsandbytes\"], check=True)\n",
    "    \n",
    "    from transformers import BitsAndBytesConfig\n",
    "    \n",
    "    # Configure 4-bit quantization\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    # Load GPT-2 model with quantization\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"gpt2\",\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "    print(\"Loaded model with 4-bit quantization\")\n",
    "else:\n",
    "    # Load GPT-2 model in full precision for CPU\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "    model = model.to(device)\n",
    "    print(f\"Loaded model in full precision on {device}\")\n",
    "\n",
    "# Load GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Disable cache for training\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Display model architecture\n",
    "print(f\"\\nModel parameters: {model.num_parameters():,}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6-data-header",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We use the UltraFeedback Binarized dataset, which contains prompts with chosen (preferred) and rejected prompt responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b91a42-74f6-4004-bcf7-93fbc9fdae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ultrafeedback_binarized dataset\n",
    "ds = load_dataset(\"BarraHome/ultrafeedback_binarized\")\n",
    "print(\"Dataset keys:\", ds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b242006-0b17-4761-b792-ba81867a9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the structure of the dataset\n",
    "print(\"Keys in first entry:\", ds[\"train_prefs\"][0].keys())\n",
    "print(\"\\nExample entry:\")\n",
    "ds[\"train_prefs\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bebb5-8206-4ee3-b8dd-c07bc0f019d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataset for faster training (adjust cnt for your needs)\n",
    "cnt = 50  # Number of examples to use\n",
    "for key in ds:\n",
    "    ds[key] = ds[key].select(range(min(cnt, len(ds[key]))))\n",
    "\n",
    "def process(row):\n",
    "    \"\"\"Process dataset row for DPO training format.\"\"\"\n",
    "    # Remove unnecessary fields\n",
    "    del row[\"prompt_id\"]\n",
    "    del row[\"messages\"]\n",
    "    del row[\"score_chosen\"]\n",
    "    del row[\"score_rejected\"]\n",
    "    \n",
    "    # Keep only the last message content for chosen and rejected responses\n",
    "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
    "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
    "    return row\n",
    "\n",
    "# Process the dataset\n",
    "ds = ds.map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "\n",
    "# Split into training and evaluation sets\n",
    "train_dataset = ds['train_prefs']\n",
    "eval_dataset = ds['test_prefs']\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a60015-b361-4648-8cd6-f3d7b2549b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine processed training data\n",
    "print(\"Processed training example:\")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6g7-lora-header",
   "metadata": {},
   "source": [
    "## LoRA Configuration\n",
    "\n",
    "We use Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning (PEFT). This allows us to train only a small number of additional parameters while keeping the base model frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dade1c-f93d-4a99-8498-a188e02a5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=4,                              # Rank of the low-rank matrices\n",
    "    target_modules=['c_proj', 'c_attn'],  # GPT-2 attention modules\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_alpha=8,                     # Scaling factor\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "print(\"LoRA Configuration:\")\n",
    "print(f\"  Rank (r): {peft_config.r}\")\n",
    "print(f\"  Alpha: {peft_config.lora_alpha}\")\n",
    "print(f\"  Target modules: {peft_config.target_modules}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8-training-header",
   "metadata": {},
   "source": [
    "## DPO Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1fc707-0a57-4e69-845d-13555fc3675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure DPO training\n",
    "training_args = DPOConfig(\n",
    "    beta=0.2,                         # DPO temperature parameter\n",
    "    output_dir=\"dpo\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    remove_unused_columns=False,\n",
    "    logging_steps=10,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    eval_strategy=\"epoch\",            # Note: 'evaluation_strategy' is deprecated\n",
    "    warmup_steps=2,\n",
    "    fp16=False,\n",
    "    save_steps=500,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f702cb-da50-459f-82de-8c2d598072fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DPO trainer\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,                   # Not needed when using LoRA\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,       # Note: 'tokenizer' param is deprecated\n",
    "    peft_config=peft_config,\n",
    "    max_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5849974-b7dd-4c91-bae6-e12132cb23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting DPO training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6g7h8i9-viz-header",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843de4cf-1254-430c-bc8b-ba9ccabfa345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and evaluation loss\n",
    "log = pd.DataFrame(trainer.state.log_history)\n",
    "log_train = log[log['loss'].notna()]\n",
    "log_eval = log[log['eval_loss'].notna()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(log_train[\"epoch\"], log_train[\"loss\"], label=\"Training Loss\", marker='o')\n",
    "plt.plot(log_eval[\"epoch\"], log_eval[\"eval_loss\"], label=\"Evaluation Loss\", marker='s')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DPO Training Progress\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g7h8i9j0-inference-header",
   "metadata": {},
   "source": [
    "## Model Inference and Comparison\n",
    "\n",
    "Let's compare the outputs of the DPO-finetuned model with the base GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69ae85-a644-4dc2-9fe9-4d9bd8ed40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest checkpoint\n",
    "import os\n",
    "import glob\n",
    "\n",
    "checkpoints = glob.glob('./dpo/checkpoint-*')\n",
    "if checkpoints:\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
    "    print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
    "    dpo_model = AutoModelForCausalLM.from_pretrained(latest_checkpoint)\n",
    "else:\n",
    "    print(\"No checkpoint found, using the trained model directly\")\n",
    "    dpo_model = trainer.model\n",
    "\n",
    "# Move to appropriate device\n",
    "dpo_model = dpo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b5ecf-ae46-4803-9941-7c2894b7aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload tokenizer for inference\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfb3db-a455-46c0-9ef2-a0522a701e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Configure generation parameters\n",
    "generation_config = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    top_k=2,\n",
    "    temperature=0.2,\n",
    "    max_new_tokens=25,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Test prompt\n",
    "PROMPT = \"Is a higher octane gasoline better for your car?\"\n",
    "inputs = tokenizer(PROMPT, return_tensors='pt').to(device)\n",
    "\n",
    "# Generate with DPO model\n",
    "outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
    "print(\"DPO response:\\t\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "# Generate with base GPT-2 model\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained('gpt2').to(device)\n",
    "outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
    "print(\"\\nGPT-2 response:\\t\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8i9j0k1-part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: Training with User Preferences Dataset\n",
    "\n",
    "In this next phase we conduct a DPO training using a user preference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd89e930-81dc-4012-9c77-f92de1a02ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load alternative user preferences dataset\n",
    "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\")\n",
    "print(f\"Dataset size: {len(dataset['train'])} examples\")\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567080e-efb3-4f59-ac7c-33b1eae3ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset for training\n",
    "cnt = 100  # Adjust based on available compute\n",
    "dataset['train'] = dataset['train'].select(range(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc09c8-10c3-48d9-a8b8-639a3ae93e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_preferences(row):\n",
    "    \"\"\"Process user preference dataset row.\"\"\"\n",
    "    # Remove unwanted columns\n",
    "    del row[\"source\"]\n",
    "    del row[\"chosen-rating\"]\n",
    "    del row[\"chosen-model\"]\n",
    "    del row[\"rejected-rating\"]\n",
    "    del row[\"rejected-model\"]\n",
    "    \n",
    "    # Extract response content\n",
    "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
    "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
    "    return row\n",
    "\n",
    "# Process the dataset\n",
    "dataset['train'] = dataset['train'].map(\n",
    "    process_preferences,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb862a-8127-4ae1-b1b8-ae706add4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and evaluation sets (80/20)\n",
    "train_size = int(0.8 * len(dataset['train']))\n",
    "eval_size = len(dataset['train']) - train_size\n",
    "\n",
    "train_dataset_v2 = dataset['train'].select(range(train_size))\n",
    "eval_dataset_v2 = dataset['train'].select(range(train_size, train_size + eval_size))\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset_v2)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset_v2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd2eb0-71fc-4b2b-81e1-faf8180c59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine processed data\n",
    "print(\"Sample processed entry:\")\n",
    "train_dataset_v2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2-comparison-header",
   "metadata": {},
   "source": [
    "## Response Generation Functions\n",
    "\n",
    "We use a helper functions to compare DPO and base GPT-2 responses to see the difference between the the fine-tuned model and baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7f0b4-9adf-4a08-80e7-55cba40afa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation configuration for comparison\n",
    "comparison_config = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    top_k=1,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=25,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393963fc-2bdf-49db-9389-ee1070a72c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dpo_response(prompt):\n",
    "    \"\"\"Generate response using DPO-finetuned model.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    outputs = dpo_model.generate(**inputs, generation_config=comparison_config)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456c943-5247-43f2-b397-5bf5f32a28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt2_response(prompt):\n",
    "    \"\"\"Generate response using base GPT-2 model.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    outputs = gpt2_model.generate(**inputs, generation_config=comparison_config)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6704981-b5cb-4141-b0d3-3a6417b8d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a custom prompt\n",
    "test_prompt = \"What is the best way to learn programming?\"\n",
    "\n",
    "print(f\"Prompt: {test_prompt}\\n\")\n",
    "print(\"DPO response:\\t\", generate_dpo_response(test_prompt))\n",
    "print(\"\\nGPT-2 response:\\t\", generate_gpt2_response(test_prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
